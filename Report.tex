\documentclass{article}
\usepackage{graphicx} 
\usepackage{geometry}
\geometry{left=1in, right=1in, top=1in, bottom=1in}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}
\usepackage{minted}

\title{Matrix Transpose using MPI}
\author{Biwei Tang, Yunxiang Yan, Qidian Gao}
\date{March 15, 2024}

\begin{document}

\maketitle

\section{Introduction}
In this project, we implement a parallel matrix transpose operation using MPI (Message Passing Interface). The program reads a square matrix from an input file, transposes the matrix using a specified algorithm, and writes the transposed matrix to an output file. We implement two algorithms for the all-to-all communication primitive: one using hypercubic permutations (HPC\_Alltoall\_H) and the other using arbitrary permutations (HPC\_Alltoall\_A). We compare the runtime of transposing the matrix using our all-to-all implementations and MPI\_Alltoall.

\section{Implementation Details}
Our program is written in C++ and uses MPI for parallel processing. The main components of our implementation are:

\begin{itemize}
    \item \texttt{readMatrix}: Reads the input matrix from a file.
    \item \texttt{writeMatrix}: Writes the transposed matrix to a file.
    \item \texttt{localTranspose}: Transposes the local matrix block.
    \item \texttt{localShuffle}: Shuffles the local matrix block.
    \item \texttt{inplaceShuffle}: Performs an in-place shuffle of the matrix block.
    \item \texttt{HPC\_Alltoall\_A}: Implements the all-to-all arbitrary permutation algorithm.
    \item \texttt{HPC\_Alltoall\_H}: Implements the hypercubic all-to-all algorithm.
\end{itemize}

The program is structured such that the process with rank 0 reads the input matrix from the file and distributes the rows among all processes using \texttt{MPI\_Scatter}. The timer is started after the data has been distributed and stopped before gathering the transposed matrix to write to the output file.

\section{Performance Evaluation}
We experimentally evaluate and compare the performance of our program with varying input matrix sizes. For $p = 8$ and $p = 16$, we plot the run-time of matrix transpose using both our all-to-all implementations and \texttt{MPI\_Alltoall} as a function of the problem size.

% TODO: Insert the plots and analysis here

\section{Space and Time Complexity Analysis}
% TODO: Provide the theoretical space and time complexity analysis for both all-to-all implementations and the matrix transpose

\section{Observations and Conclusion}
% TODO: Discuss any important observations, irregular or unexpected results, and conclusions based on the performance evaluation

\section{Contributions}
The contributions of each team member are listed in the table below:

\begin{table}[H]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Team Member} & \textbf{Contribution} \\
\hline
Biwei Tang & Implemented the arbitrary all-to-all algorithm \\
\hline
Yunxiang Yan & Implemented the hypercubic all-to-all algorithm \\
\hline
Qidian Gao & Conducted performance evaluation and prepared the report \\
\hline
\end{tabular}
\end{table}

\end{document}